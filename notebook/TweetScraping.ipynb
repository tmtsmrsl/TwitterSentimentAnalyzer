{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsbaR36eluJs"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpU0DMr1bzKz",
        "outputId": "374da20f-ef14-4121-eed8-819d46c36376"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting snscrape\n",
            "  Downloading snscrape-0.4.3.20220106-py3-none-any.whl (59 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.1 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from snscrape) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from snscrape) (3.8.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from snscrape) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from snscrape) (4.9.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from snscrape) (2022.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (1.7.1)\n",
            "Installing collected packages: snscrape\n",
            "Successfully installed snscrape-0.4.3.20220106\n"
          ]
        }
      ],
      "source": [
        "!pip install snscrape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ywtVii1uddWj"
      },
      "outputs": [],
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import datetime as dt\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NfIWScXlwvE"
      },
      "source": [
        "## Scrape tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiHLfPCwmO4f"
      },
      "source": [
        "Scrape 365k positive (using \":)\" as the query) and 365k negative (using \":(\" as the query) tweets from year 2022. We will scrape 1000 tweets per day for each category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvikYVSAc_3K"
      },
      "outputs": [],
      "source": [
        "def scrape_tweet(search_term, start_date, end_date, num_tweets):\n",
        "    start_date = start_date.strftime(\"%Y-%m-%d\")\n",
        "    end_date = end_date.strftime(\"%Y-%m-%d\")\n",
        "    tweet_data = []\n",
        "    for i, tweet in enumerate(\n",
        "        sntwitter.TwitterSearchScraper(\n",
        "            \"{} since:{} until:{} lang:en exclude:retweets\".format(\n",
        "                search_term, start_date, end_date\n",
        "            )\n",
        "        ).get_items()\n",
        "    ):\n",
        "        if i >= num_tweets:\n",
        "            break\n",
        "        tweet_data.append([tweet.user.username, tweet.date, tweet.content])\n",
        "    tweet_df = pd.DataFrame(tweet_data, columns=[\"username\", \"date\", \"tweet\"])\n",
        "    return tweet_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aolFlfnhUVkD"
      },
      "outputs": [],
      "source": [
        "def daily_scrape_2022(search_term, num_daily):\n",
        "    start_date = dt.datetime(2022, 1, 1)\n",
        "    end_date = dt.datetime(2022, 1, 2)\n",
        "    delta = dt.timedelta(days=1)\n",
        "    df = pd.DataFrame()\n",
        "    for n in range(365):\n",
        "        temp_df = scrape_tweet(search_term, start_date, end_date, num_daily)\n",
        "        df = pd.concat([df, temp_df])\n",
        "        start_date += delta\n",
        "        end_date += delta\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gv9gRwwOU-Xj"
      },
      "outputs": [],
      "source": [
        "ori_neg_df = daily_scrape_2022(\":(\", 1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZ1l45BgVO18"
      },
      "outputs": [],
      "source": [
        "ori_pos_df = daily_scrape_2022(\":)\", 1000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsRu_eFemImS"
      },
      "source": [
        "## Filter scraped tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pH8jHuVXXr5n"
      },
      "outputs": [],
      "source": [
        "def filter_include(df, term_list):\n",
        "    temp_df = pd.DataFrame()\n",
        "    for term in term_list:\n",
        "        add_df = df[df[\"tweet\"].str.contains(term, regex=False) == True]\n",
        "        temp_df = pd.concat([temp_df, add_df]).drop_duplicates(ignore_index=True)\n",
        "    return temp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymaioN-NV0XR"
      },
      "outputs": [],
      "source": [
        "def filter_exclude(df, term_list):\n",
        "    temp_df = df.copy()\n",
        "    for term in term_list:\n",
        "        temp_df = temp_df[temp_df[\"tweet\"].str.contains(term, regex=False) == False]\n",
        "    return temp_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRNtDD9ouKY8"
      },
      "source": [
        "Filter negative tweet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv0fhp3CZIIZ",
        "outputId": "a13341b2-cc9f-45aa-f6e7-9f9c74d18ef5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(358624, 3)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "neg_df = filter_include(ori_neg_df, [\":(\", \":-(\"])\n",
        "neg_df = filter_exclude(neg_df, [\":)\", \":D\", \":-)\"])\n",
        "neg_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9c-PW7Svj7k"
      },
      "source": [
        "Filter positive tweet "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPsMSowWZpSw",
        "outputId": "f8e29997-1f83-4410-b759-6a7f8e8cda19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(343477, 3)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos_df = filter_include(ori_pos_df, [\":)\", \":D\", \":-)\"])\n",
        "pos_df = filter_exclude(pos_df, [\":(\", \":-(\"])\n",
        "pos_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aANr9lUFgdKQ"
      },
      "source": [
        "## Remove emojis from tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAi-FFwpghg4"
      },
      "source": [
        "Remove all emojis because we want our model to classify the tweet sentiment from the text instead of emojis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANcprsmcgxsS"
      },
      "outputs": [],
      "source": [
        "def remove_term(df, term_list):\n",
        "    temp_df = df.copy()\n",
        "    for term in term_list:\n",
        "        temp_df[\"tweet\"] = temp_df[\"tweet\"].str.replace(term, \" \", regex=False)\n",
        "    return temp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhVRQS0LhsoS"
      },
      "outputs": [],
      "source": [
        "neg_df = remove_term(neg_df, [\":(\", \":-(\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROLfkBXkhy8H"
      },
      "outputs": [],
      "source": [
        "pos_df = remove_term(pos_df, [\":)\", \":D\", \":-)\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8_7ZDiMj1bq"
      },
      "source": [
        "## Label tweets and merge them into a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lPA50lVkID8"
      },
      "outputs": [],
      "source": [
        "neg_df[\"sentiment\"] = \"Negative\"\n",
        "pos_df[\"sentiment\"] = \"Positive\"\n",
        "df = pd.concat([neg_df, pos_df]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaMznaF6kQ7k"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"/content/drive/MyDrive/dataset/labeled_tweets.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "9be1022a05af415b4028b92ecacc354b62c054b161aeb0bf6140aaf31badf13b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
