{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# End-to-End Machine Learning Project: Twitter Sentiment Analysis - Introduction and Data Collection (Part 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As someone who does not come from a math, statistics, or computer science background, I believe that creating a portfolio project is a great way to showcase our skills and abilities in data science. In this post, I want to share an example of an end-to-end machine learning project on sentiment analysis, which is a rapidly growing field in natural language processing and machine learning. We will go over the entire process, from data collection and preprocessing to model building, creating a dashboard, and finally deploying the model and dashboard as an online application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before collecting the data, we need to define the objective of our project. Our objective is to predict the public's sentiment about a brand (product, service, company or person) based on tweet data. We will use the data collection methodology described in [this paper](https://www-cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf) (Twitter Sentiment Classification using Distant Supervision, Go, Bhayani, & Huang, 2009). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Distant supervision is a method that utilizes a set of rules to automatically label a dataset. Since it does not require human intervention, it can save a lot of time and resources, especially when working with large datasets. In our case, we will use emoticons to label the sentiment of the tweet. Specifically, a tweet with a smiley face will be labeled as positive, and a tweet with a frowning face will be labeled negative. We will use a library called `snscrape` to collect the tweets; it does not require using the Twitter API, so we can retrieve a large amount of tweets without worrying about the [rate limit](https://developer.twitter.com/en/docs/twitter-api/rate-limits). In the following section we will walk through the code and explain the logic behind it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Disclaimer: As of 11 January 2023, Twitter modified its frontend API and the code below will no longer work. I will provide an alternative as soon as I find a solution.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsbaR36eluJs"
      },
      "source": [
        "First we will import the necessary libraries, please install them first if you do not already have them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpU0DMr1bzKz",
        "outputId": "374da20f-ef14-4121-eed8-819d46c36376"
      },
      "outputs": [],
      "source": [
        "!pip install snscrape\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import datetime as dt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NfIWScXlwvE"
      },
      "source": [
        "Then we will make a function that utilizes `sntwitter.TwitterSearchScraper` to retrieve the tweets and save them in a dataframe. The function takes the following arguments:  \n",
        "* search_term: the term you want to search for on Twitter\n",
        "* start_date: the start date of the search range in the format of datetime.date object\n",
        "* end_date: the end date of the search range in the format of datetime.date object\n",
        "* num_tweets: the number of tweets you want to retrieve\n",
        "\n",
        "A `for` loop is used to iterate over and store the tweet data (username, date, and tweet content) returned by the `get_items` method of `sntwitter.TwitterSearchScraper`. We use lang:en (English language) and exclude:retweets as the search filters. The tweet data is finally returned as a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvikYVSAc_3K"
      },
      "outputs": [],
      "source": [
        "def scrape_tweet(search_term, start_date, end_date, num_tweets):\n",
        "    start_date = start_date.strftime(\"%Y-%m-%d\")\n",
        "    end_date = end_date.strftime(\"%Y-%m-%d\")\n",
        "    tweet_data = []\n",
        "    for i, tweet in enumerate(sntwitter.TwitterSearchScraper('{} since:{} until:{} lang:en exclude:retweets'.format(search_term, start_date, end_date)).get_items()):\n",
        "        if i >= num_tweets:\n",
        "            break\n",
        "        tweet_data.append([tweet.user.username, tweet.date, tweet.content])\n",
        "    tweet_df = pd.DataFrame(tweet_data, columns=['username', 'date', 'tweet'])\n",
        "    return tweet_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this project, we want to retrieve tweets from 2022-01-01 to 2022-12-31. So we make another function, `daily_scrape_2022` which utilizes the `scrape_tweet` function to retrieve tweets for each day in 2022. We can specify the number of tweets we want to retrieve for each day using `num_daily`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aolFlfnhUVkD"
      },
      "outputs": [],
      "source": [
        "def daily_scrape_2022(search_term, num_daily):\n",
        "    start_date = dt.datetime(2022, 1, 1)\n",
        "    end_date = dt.datetime(2022, 1, 2)\n",
        "    delta = dt.timedelta(days=1)\n",
        "    df = pd.DataFrame()\n",
        "    for n in range(365):\n",
        "        temp_df = scrape_tweet(search_term, start_date, end_date, num_daily)\n",
        "        df = pd.concat([df, temp_df])\n",
        "        start_date += delta\n",
        "        end_date += delta\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will use the `daily_scrape_2022` function to retrieve 1000 tweets daily for each day in 2022. Tweets with negative sentiment will be searched with the term \":(\" while tweets with positive sentiment will be searched with the term \":)\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gv9gRwwOU-Xj"
      },
      "outputs": [],
      "source": [
        "ori_neg_df = daily_scrape_2022(\":(\", 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZ1l45BgVO18"
      },
      "outputs": [],
      "source": [
        "ori_pos_df = daily_scrape_2022(\":)\", 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsRu_eFemImS"
      },
      "source": [
        "The retrieved tweets do not always contain the specified search term, so we need to do some filtering. We create two functions, one to include tweets containing specific terms and the other to exclude tweets containing specific terms.Â "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pH8jHuVXXr5n"
      },
      "outputs": [],
      "source": [
        "def filter_include(df, terms):\n",
        "    temp_df = pd.DataFrame()\n",
        "    for term in terms:\n",
        "        add_df = df[df['tweet'].str.contains(term, regex=False) == True]\n",
        "        temp_df = pd.concat([temp_df, add_df]).drop_duplicates(ignore_index=True)\n",
        "    return temp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymaioN-NV0XR"
      },
      "outputs": [],
      "source": [
        "def filter_exclude(df, terms):\n",
        "    temp_df = df.copy()\n",
        "    for term in terms:\n",
        "        temp_df = temp_df[temp_df['tweet'].str.contains(term, regex=False) == False]\n",
        "    return temp_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRNtDD9ouKY8"
      },
      "source": [
        "For the negative tweets, we will "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv0fhp3CZIIZ",
        "outputId": "a13341b2-cc9f-45aa-f6e7-9f9c74d18ef5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(358624, 3)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "neg_df = filter_include(ori_neg_df, [\":(\", \":-(\"])\n",
        "neg_df = filter_exclude(neg_df, [\":)\", \":D\", \":-)\"])\n",
        "neg_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9c-PW7Svj7k"
      },
      "source": [
        "Filter positive tweet "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPsMSowWZpSw",
        "outputId": "f8e29997-1f83-4410-b759-6a7f8e8cda19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(343477, 3)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos_df = filter_include(ori_pos_df, [\":)\", \":D\", \":-)\"])\n",
        "pos_df = filter_exclude(pos_df, [\":(\", \":-(\"])\n",
        "pos_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aANr9lUFgdKQ"
      },
      "source": [
        "## Remove emojis from tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAi-FFwpghg4"
      },
      "source": [
        "Remove all emojis because we want our model to classify the tweet sentiment from the text instead of emojis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANcprsmcgxsS"
      },
      "outputs": [],
      "source": [
        "def remove_term(df, terms):\n",
        "    temp_df = df.copy()\n",
        "    for term in terms:\n",
        "        temp_df['tweet'] = temp_df['tweet'].str.replace(term, \" \", regex=False)\n",
        "    return temp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhVRQS0LhsoS"
      },
      "outputs": [],
      "source": [
        "neg_df = remove_term(neg_df, [\":(\", \":-(\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROLfkBXkhy8H"
      },
      "outputs": [],
      "source": [
        "pos_df = remove_term(pos_df, [\":)\", \":D\", \":-)\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8_7ZDiMj1bq"
      },
      "source": [
        "## Label tweets and merge them into a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lPA50lVkID8"
      },
      "outputs": [],
      "source": [
        "neg_df[\"sentiment\"] = \"Negative\"\n",
        "pos_df[\"sentiment\"] = \"Positive\"\n",
        "df = pd.concat([neg_df, pos_df]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaMznaF6kQ7k"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"../dataset/labeled_tweets.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "9be1022a05af415b4028b92ecacc354b62c054b161aeb0bf6140aaf31badf13b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
